{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Handle the necessary imports'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after importing libraries, we load and check if the images are properly displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor index in range(1):\\n    loaded_image_aflw=cv2.imread(\\'Data//AFLW//positive_faces//positive_face_\\'+str(index)+\\'.png\\')  # load the image from disk for AFLW dataset\\n    loaded_image_lfw=cv2.imread(\\'Data//LFW//positive_faces//positive_face_\\'+str(index)+\\'.png\\')  # load the image from disk for LFW dataset\\n    cv2.imshow(\"Loaded Image\",loaded_image_aflw) # show image\\n    cv2.waitKey(5000)\\ncv2.destroyAllWindows()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aflw_image = []\n",
    "for img in glob.glob(\"Data//AFLW//positive_faces//*.png\"):\n",
    "    n= cv2.imread(img)\n",
    "    aflw_image.append(n)\n",
    "    \n",
    "print(len(aflw_image))\n",
    "\n",
    "cv2.imshow(\"Image\",aflw_image[1])\n",
    "cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\"\"\"\n",
    "for index in range(1):\n",
    "    loaded_image_aflw=cv2.imread('Data//AFLW//positive_faces//positive_face_'+str(index)+'.png')  # load the image from disk for AFLW dataset\n",
    "    loaded_image_lfw=cv2.imread('Data//LFW//positive_faces//positive_face_'+str(index)+'.png')  # load the image from disk for LFW dataset\n",
    "    cv2.imshow(\"Loaded Image\",loaded_image_aflw) # show image\n",
    "    cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tested load and display of the images,we can proceed with resizing and the training and test data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_size=60 #60*60*3\n",
    "num_training_images=1000\n",
    "num_testing_images=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index=0\n",
    "while index<num_training_images:\n",
    "    loaded_image=cv2.imread('Data//AFLW//positive_faces//positive_face_'+str(index)+'.png')  # load the image from disk \n",
    "    resized_image=cv2.resize(loaded_image,(patch_size,patch_size),cv2.INTER_LANCZOS4) #resize it\n",
    "    cv2.imwrite('Data//AFLW//extracted_faces//train//train_face'+str(index)+'.png',resized_image)  # save the image to disk \n",
    "    #repeat for non-faces \n",
    "    #loaded_image=cv2.imread('Data//WIDER_train//images//0--Parade'+str(index)+'.png')  # load the image from disk \n",
    "    #resized_image=cv2.resize(loaded_image,(patch_size,patch_size),cv2.INTER_LANCZOS4) #resize it\n",
    "    #cv2.imwrite('Data//AFLW//extracted_faces//train_face'+str(index)+'.png',resized_image)  # save the image to disk\n",
    "    index+=1 #increment\n",
    "    #cv2.imshow(\"Loaded Image\",resized_image) # show image\n",
    "    #cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly process for testing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index=1000\n",
    "while index<num_testing_images+num_training_images:\n",
    "    loaded_image=cv2.imread('Data//AFLW//positive_faces//positive_face_'+str(index)+'.png')  # load the image from disk \n",
    "    resized_image=cv2.resize(loaded_image,(patch_size,patch_size),cv2.INTER_LANCZOS4) #resize it\n",
    "    cv2.imwrite('Data//AFLW//extracted_faces//test//test_face'+str(index-num_training_images)+'.png',resized_image)  # save the image to disk \n",
    "    #repeat for non-faces \n",
    "    #loaded_image=cv2.imread('Data//WIDER_train//images//0--Parade'+str(index)+'.png')  # load the image from disk \n",
    "    #resized_image=cv2.resize(loaded_image,(patch_size,patch_size),cv2.INTER_LANCZOS4) #resize it\n",
    "    #cv2.imwrite('Data//AFLW//extracted_faces//train_face'+str(index)+'.png',resized_image)  # save the image to disk\n",
    "    index+=1 #increment\n",
    "    #cv2.imshow(\"Loaded Image\",resized_image) # show image\n",
    "    #cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed with training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARE TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1. Learn single Gaussian model using training images and report your results as stated\n",
    "above.\n",
    "\n",
    "For a single gaussian model, we have the equation as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10800)\n",
      "(1000, 10800)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single gaussian model\n",
    "# Convention, Y-outputs/labels and X-inputs/features\n",
    "def GMM_train(X,max_iterations=100):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "def demo_2d():\n",
    "    \n",
    "    # Load data\n",
    "    #X = np.genfromtxt('data1.csv', delimiter=',')\n",
    "    ### generate the random data     \n",
    "    np.random.seed(3)\n",
    "    m1, cov1 = [9, 8], [[.5, 1], [.25, 1]] ## first gaussian\n",
    "    data1 = np.random.multivariate_normal(m1, cov1, 90)\n",
    "    \n",
    "    m2, cov2 = [6, 13], [[.5, -.5], [-.5, .1]] ## second gaussian\n",
    "    data2 = np.random.multivariate_normal(m2, cov2, 45)\n",
    "    \n",
    "    m3, cov3 = [4, 7], [[0.25, 0.5], [-0.1, 0.5]] ## third gaussian\n",
    "    data3 = np.random.multivariate_normal(m3, cov3, 65)\n",
    "    X = np.vstack((data1,np.vstack((data2,data3))))\n",
    "    np.random.shuffle(X)\n",
    "#    np.savetxt('sample.csv', X, fmt = \"%.4f\",  delimiter = \",\")\n",
    "    ####\n",
    "    gmm = GMM(3, 0.000001)\n",
    "    params = gmm.fit_EM(X, max_iters= 100)\n",
    "    print (params.log_likelihoods)\n",
    "    import pylab as plt    \n",
    "    from matplotlib.patches import Ellipse\n",
    "    \n",
    "    def plot_ellipse(pos, cov, nstd=2, ax=None, **kwargs):\n",
    "        def eigsorted(cov):\n",
    "            vals, vecs = np.linalg.eigh(cov)\n",
    "            order = vals.argsort()[::-1]\n",
    "            return vals[order], vecs[:,order]\n",
    "    \n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "    \n",
    "        vals, vecs = eigsorted(cov)\n",
    "        theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "    \n",
    "        # Width and height are \"full\" widths, not radius\n",
    "        width, height = 2 * nstd * np.sqrt(abs(vals))\n",
    "        ellip = Ellipse(xy=pos, width=width, height=height, angle=theta, **kwargs)\n",
    "    \n",
    "        ax.add_artist(ellip)\n",
    "        return ellip    \n",
    "    \n",
    "    def show(X, mu, cov):\n",
    "\n",
    "        plt.cla()\n",
    "        K = len(mu) # number of clusters\n",
    "        colors = ['b', 'k', 'g', 'c', 'm', 'y', 'r']\n",
    "        plt.plot(X.T[0], X.T[1], 'm*')\n",
    "        for k in range(K):\n",
    "          plot_ellipse(mu[k], cov[k],  alpha=0.6, color = colors[k % len(colors)])  \n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize = (13, 6))\n",
    "    fig.add_subplot(121)\n",
    "    show(X, params.mu, params.Sigma)\n",
    "    fig.add_subplot(122)\n",
    "    plt.plot(np.array(params.log_likelihoods))\n",
    "    plt.title('Log Likelihood vs iteration plot')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('log likelihood')\n",
    "    plt.show()\n",
    "    print (gmm.predict(np.array([1, 2])))\n",
    "       \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    demo_2d()    \n",
    "    from optparse import OptionParser\n",
    "\n",
    "    parser = OptionParser()\n",
    "    parser.add_option(\"-f\", \"--file\", dest=\"filepath\", help=\"File path for data\")\n",
    "    parser.add_option(\"-k\", \"--clusters\", dest=\"clusters\", help=\"No. of gaussians\")    \n",
    "    parser.add_option(\"-e\", \"--eps\", dest=\"epsilon\", help=\"Epsilon to stop\")    \n",
    "    parser.add_option(\"-m\", \"--maxiters\", dest=\"max_iters\", help=\"Maximum no. of iteration\")        \n",
    "    options, args = parser.parse_args()\n",
    "    \n",
    "    if not options.filepath : raise('File not provided')\n",
    "    \n",
    "    if not options.clusters :\n",
    "        print(\"Used default number of clusters = 3\" )\n",
    "        k = 3\n",
    "    else: k = int(options.clusters)\n",
    "    \n",
    "    if not options.epsilon :\n",
    "        print(\"Used default eps = 0.0001\" )\n",
    "        eps = 0.0001\n",
    "    else: eps = float(options.epsilon)\n",
    "    \n",
    "    if not options.max_iters :\n",
    "        print(\"Used default maxiters = 1000\" )\n",
    "        max_iters = 1000\n",
    "    else: eps = int(options.maxiters)\n",
    "    \n",
    "    #X = np.genfromtxt(options.filepath, delimiter=',')\n",
    "    gmm = GMM(k, eps)\n",
    "    X=training_data_face(0,0:100)\n",
    "    params = gmm.fit_EM(X, max_iters)\n",
    "    print (params.log_likelihoods)\n",
    "    gmm.plot_log_likelihood()\n",
    "    print (gmm.predict(np.array([1, 2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
